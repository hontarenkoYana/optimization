Optimization methods.
=====================
**One-dimensional methods:**
1. [Method of dichotomy](https://www.encyclopediaofmath.org/index.php/Dichotomy_method).
2. [Method of golden section](https://en.wikipedia.org/wiki/Golden-section_search).
3. [Method chord](http://egyankosh.ac.in/bitstream/123456789/18067/1/Unit-3.pdf).
4. [Midpoint method](https://en.wikipedia.org/wiki/Midpoint_method).
5. [Newton-Raphson method](http://butler.cc.tut.fi/~piche/numa/lecture0506.pdf).
*Input*: 
- a, b - segment on which should be the solution of the equation;
- delta - small number;
- eps - accuracy of the solution;
- x0 - starting point.
*Result*:
- point-solution;
- resut of function in this point;
- how many iteration was.
**Manydimensional methods:**
1. [Method coordinate descent](https://en.wikipedia.org/wiki/Coordinate_descent).
2. [Method of gradient descent](https://en.wikipedia.org/wiki/Gradient_descent).
3. [Method of configuration(Hooke-Jeeves)](https://www.researchgate.net/publication/266053442_Application_of_Hooke_Jeeves_Algorithm_in_Optimizing_Fusion_Zone_Grain_Size_and_Hardness_of_Pulsed_Current_Micro_Plasma_Arc_Welded_AISI_304L_Sheets).
4. [Nelder-Mead method](https://en.wikipedia.org/wiki/Nelder%E2%80%93Mead_method).

*Input*: 
- x0 - starting point;
- eps - accuracy of the solution;
- *in Nelder-Mead method* x1, x2, x3 - point of triangle.

*Result*:
- point-solution;
- resut of function in this point;
- how many iteration was.
